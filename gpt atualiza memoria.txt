carregar em memória a estrutura dos diretórios do projeto e os códigos:

# Directory Structure:
# - domain/
#   - __init__.py
#   - audio_analysis.py
# - application/
#   - __init__.py
#   - services.py
# - adapters/
#   - __init__.py
#   - web.py
# - frontend/
#   - index.html
#   - app.js
#   - styles.css
#   - service-worker.js
#   - audio-editor.js
#   - assets/
#     - phonIA_logo.png
#     - logo.png
#     - logo-192x192.png
#     - logo-512x512.png
#     - manifest.json
#   - templates/
#     - base.html
#     - consent.html
#     - home.html
#     - page1.html
#     - page2.html
#     - page3.html
#     - page4.html
# - api/
#   - main.py


# --- domain/audio_analysis.py ---
from pydantic import BaseModel
import parselmouth
from parselmouth.praat import call
import numpy as np
from scipy.signal import find_peaks
import matplotlib.pyplot as plt
import pandas as pd
import plotly.graph_objects as go
from pydub import AudioSegment
from pydub.effects import normalize


class AudioAnalysisResult(BaseModel):
    jitter: float  # remover depois
    localJitter: float
    localabsoluteJitter: float
    rapJitter: float
    ppq5Jitter: float
    ddpJitter: float
    shimmer: float # remover depois
    localShimmer: float
    localdbShimmer: float
    apq3Shimmer: float
    apq5Shimmer: float
    apq11Shimmer: float
    ddaShimmer: float
    fundamental_frequency: float
    # harmonicity: float
    hnr: float
    frequencies: list
    amplitudes: list


class AudioAnalyzer:
    audio_input: str =''
    audio_norm: str =''

    def analyze(self, audio_path: str) -> AudioAnalysisResult:
        try:
            self.audio_input = audio_path

            # Normaliza o áudio
            self.audio_norm = self.normalize_audio(audio_path)

            sound = parselmouth.Sound(self.audio_norm)
            pointProcess = parselmouth.praat.call(sound, "To PointProcess (periodic, cc)", 75, 500)

            # NOVOS PARAMS COMPLETOS:
            # Jitter PARAMS
            localJitter = call(pointProcess, "Get jitter (local)", 0, 0, 0.0001, 0.02, 1.3) * 100
            localabsoluteJitter = call(pointProcess, "Get jitter (local, absolute)", 0, 0, 0.0001, 0.02, 1.3)
            rapJitter = call(pointProcess, "Get jitter (rap)", 0, 0, 0.0001, 0.02, 1.3) * 100
            ppq5Jitter = call(pointProcess, "Get jitter (ppq5)", 0, 0, 0.0001, 0.02, 1.3) * 100
            ddpJitter = call(pointProcess, "Get jitter (ddp)", 0, 0, 0.0001, 0.02, 1.3) * 100

            # Shimmer PARAMS
            localShimmer =  call([sound, pointProcess], "Get shimmer (local)", 0, 0, 0.0001, 0.02, 1.3, 1.6) * 100
            localdbShimmer = call([sound, pointProcess], "Get shimmer (local_dB)", 0, 0, 0.0001, 0.02, 1.3, 1.6)
            apq3Shimmer = call([sound, pointProcess], "Get shimmer (apq3)", 0, 0, 0.0001, 0.02, 1.3, 1.6) * 100
            apq5Shimmer = call([sound, pointProcess], "Get shimmer (apq5)", 0, 0, 0.0001, 0.02, 1.3, 1.6) * 100
            apq11Shimmer = call([sound, pointProcess], "Get shimmer (apq11)", 0, 0, 0.0001, 0.02, 1.3, 1.6) * 100
            ddaShimmer = call([sound, pointProcess], "Get shimmer (dda)", 0, 0, 0.0001, 0.02, 1.3, 1.6) * 100

 # remover depois
            # Jitter (ppq5) calculation
            jitter = call(pointProcess, "Get jitter (ppq5)", 0, 0, 0.0001, 0.02, 1.3) * 100
            # parselmouth.praat.call(pointProcess, "Get jitter (local)", 0, 0, 0.0001, 0.02, 1.3)#, 0.0001, 0.02, 0.02, 1.3)

 # remover depois
            # Shimmer (apq3) calculation
            shimmer = call([sound, pointProcess], "Get shimmer (apq3)", 0, 0, 0.0001, 0.02, 1.3, 1.6) * 100
            # parselmouth.praat.call([sound, pointProcess], "Get shimmer (local)", 0, 0, 0.0001, 0.02, 1.3, 1.6)#, 0.0001, 0.02, 0.02, 1.3)

            # Fundamental frequency calculation
            f0 = sound.to_pitch().selected_array["frequency"].mean()

            # Harmonicidade (HNR)
            harmonicity = sound.to_harmonicity()

            # aaaa = sound.to_harmonicity()
            # print('harmonicity ', type(aaaa), aaaa) # debug

            # Calcular Harmonics-to-Noise Ratio (HNR)
            hnr = call(harmonicity, "Get mean", 0, 0)


            top_freq = self.calculate_fft(audio_path)

            return AudioAnalysisResult(
                jitter=jitter,
                localJitter=localJitter,
                localabsoluteJitter=localabsoluteJitter,
                rapJitter=rapJitter,
                ppq5Jitter=ppq5Jitter,
                ddpJitter=ddpJitter,
                shimmer=shimmer,
                localShimmer=localShimmer,
                localdbShimmer=localdbShimmer,
                apq3Shimmer=apq3Shimmer,
                apq5Shimmer=apq5Shimmer,
                apq11Shimmer=apq11Shimmer,
                ddaShimmer=ddaShimmer,
                fundamental_frequency=f0,
                hnr=hnr,
                frequencies=top_freq["frequencies"],
                amplitudes=top_freq["amplitudes"]
            )

        except Exception as e:
            raise ValueError(f"Error analyzing audio: {str(e)}")

    def calculate_fft(self, audio_path: str) -> dict:
        """Calcula e plota a FFT de um arquivo de áudio e retorna as frequências e amplitudes."""
        sound = parselmouth.Sound(audio_path)
        sampling_rate = sound.sampling_frequency
        audio_data = sound.values[0]
        n = len(audio_data)

        # FFT computation
        fft_values = np.fft.fft(audio_data)
        frequencies = np.fft.fftfreq(n, d=1/sampling_rate)

        # Focus on positive frequencies
        positive_frequencies = frequencies[:n // 2]
        positive_amplitudes = np.abs(fft_values[:n // 2])

        # Distância mínima para considerar como um único grupo
        distancia_minima = 50  # Em unidades de frequência

        # Filtrar apenas frequências até 1 kHz
        limite_frequencia = 1000  # 1 kHz
        mask = positive_frequencies <= limite_frequencia
        freq_filter_freq = positive_frequencies[mask]
        amp_filter_freq = positive_amplitudes[mask]

        # Detectar picos com distância mínima de 2mil amostras
        indices_picos, _ = find_peaks(amp_filter_freq, distance=2000)

        # Filtrar os picos com base na distância mínima
        picos_filtrados = []
        frequencias_filtradas = []
        magnitudes_filtradas = []

        for i in range(len(indices_picos)):
            freq_atual = freq_filter_freq[indices_picos[i]]
            mag_atual = amp_filter_freq[indices_picos[i]]

            # Verificar se está longe o suficiente dos picos já filtrados
            if not any(abs(freq_atual - f) < distancia_minima for f in frequencias_filtradas):
                picos_filtrados.append(indices_picos[i])
                frequencias_filtradas.append(freq_atual)
                magnitudes_filtradas.append(mag_atual)

        # Exibir os resultados
        for i, (freq, mag) in enumerate(zip(frequencias_filtradas, magnitudes_filtradas)):
            print(f"{i+1}: Frequência = {freq:.2f} Hz, Valor = {mag:.2f}")

        # Plot FFT with top frequencies highlighted
        plt.figure(figsize=(10, 6))
        plt.plot(freq_filter_freq, amp_filter_freq, label="FFT")
        plt.scatter(frequencias_filtradas, magnitudes_filtradas, color='red', label="Top Peaks")
        plt.title("FFT of the Audio Signal with Top Peaks")
        plt.xlabel("Frequency (Hz)")
        plt.ylabel("Amplitude")
        plt.legend()
        plt.grid()
        plt.savefig("fft_plot.png")

        self.create_plot_fft(freq_filter_freq, amp_filter_freq, frequencias_filtradas, magnitudes_filtradas)
        self.export_to_excel(positive_frequencies, positive_amplitudes, "fft_audio.csv")
        self.export_to_excel(frequencias_filtradas, magnitudes_filtradas, "fft_audio_filtrada.csv")

        return {"frequencies": frequencias_filtradas, "amplitudes": magnitudes_filtradas}

    def create_plot_fft(self, freq_filter_freq, amp_filter_freq, frequencias_filtradas, magnitudes_filtradas) -> None:
        """Create a iterative plot in html form"""

        # Criando o gráfico interativo
        fig = go.Figure()

        fig.add_trace(go.Scatter(x=freq_filter_freq, y=amp_filter_freq, mode='lines', name='FFT'))
        fig.add_trace(go.Scatter(x=frequencias_filtradas, y=magnitudes_filtradas, mode='markers', name='Maiores Picos'))

        # Configuração do layout
        fig.update_layout(
            title=dict(text="Gráfico Interativo - FFT do Sinal de Áudio e Maiores Picos",
                       x=0.5, xanchor="center",
                       font=dict(family="Arial, sans-serif", size=20, color="black", weight="bold")),
            xaxis_title=dict(text="Frequência (Hz)",font=dict(size=16, color="black", weight="bold")),
            yaxis_title=dict(text="Amplitude",font=dict(size=16, color="black", weight="bold")),
            xaxis=dict(tickfont=dict(size=12, weight="bold")),
            yaxis=dict(tickfont=dict(size=12, weight="bold")),
            plot_bgcolor='whitesmoke', #determina a cor do fundo
            template='plotly_white', #"plotly_dark"  # Opção de tema
            legend=dict(x=0.5, y=1.1, xanchor="center", orientation="h")
        )

        # Determina a cor do eixo x e a cor do grid
        fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='gray',
        showline=True, linewidth=1, linecolor='black')

        # Determina a cor do eixo y e a cor do grid
        fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='gray',
        showline=True, linewidth=1, linecolor='black')

        # Salvar como HTML
        fig.write_html("frontend/assets/grafico_interativo.html")
        print("Gráfico salvo como 'grafico_interativo.html'.")

        return

    def export_to_excel(self, freq: list, amp: list, filename: str) -> None:
        """Export two lists into an Excel file with two columns."""
        if len(freq) != len(amp):
            raise ValueError("Both lists must have the same length.")

        # Create a DataFrame from the two lists
        data = pd.DataFrame({"freq": freq, "amp": amp})

        # Export to an Excel file
        data.to_csv(filename, index=False)
        print(f"Excel file '{filename}' has been created successfully.")
        return

    def normalize_audio(self, audio_path: str) -> str:
        """Carrega um arquivo de áudio e depois normaliza ele em relação a amplitude."""
        # Carregar o áudio
        audio = AudioSegment.from_file(audio_path)

        # Normalizar
        normalized_audio = normalize(audio)

        name_norm = self.insert_after_end_name(audio_path)
        print('teste ' + name_norm)

        # Salvar o áudio normalizado
        normalized_audio.export(name_norm, format="wav")
        return name_norm



    def insert_after_end_name(self, original:str) -> str:
        """ Inserts a string '_normalized' after the first dot in `original`."""
        if "." in original:
            index = original.find(".")  # Find the index of the .wav
            return original[:index] + '_normalized' + original[index :]  # Insert after dot
        else:
            raise ValueError("The original string does not contain an dot ('.')!!!")
	
	
# --- application/services.py ---
from domain.audio_analysis import AudioAnalyzer, AudioAnalysisResult
import sqlite3

class AudioAnalysisService:
    def __init__(self, analyzer: AudioAnalyzer):
        self.analyzer = analyzer
        self.db_path = "DB_Phonia.db"
        self._initialize_database()

    def _initialize_database(self):
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                jitter REAL,
                shimmer REAL,
                fundamental_frequency REAL
            )
        """)
        conn.commit()
        conn.close()

    def analyze_audio_file(self, file_path: str) -> AudioAnalysisResult:
        result = self.analyzer.analyze(file_path)
        self._save_to_database(result)
        return result

    def _save_to_database(self, result: AudioAnalysisResult):
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("""
            INSERT INTO analysis (jitter, shimmer, fundamental_frequency)
            VALUES (?, ?, ?)
        """, (result.jitter, result.shimmer, result.fundamental_frequency))
        conn.commit()
        conn.close()



# --- adapters/web.py ---
from fastapi import FastAPI, UploadFile, HTTPException, Request, File
from fastapi.responses import JSONResponse, HTMLResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from application.services import AudioAnalysisService
from domain.audio_analysis import AudioAnalyzer
from fastapi.templating import Jinja2Templates
import os


# Configurando os templates
templates = Jinja2Templates(directory="frontend/templates")

favicon_path = 'favicon.ico'

UPLOAD_DIR = "uploads"
os.makedirs(UPLOAD_DIR, exist_ok=True)

analyzer = AudioAnalyzer()
service = AudioAnalysisService(analyzer)

app = FastAPI()

# Mount static files
app.mount("/static", StaticFiles(directory="frontend"), name="static")

# Adicione este middleware ao seu app FastAPI
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/service-worker.js", response_class=FileResponse)
async def get_service_worker():
    return FileResponse("frontend/service-worker.js", media_type="application/javascript")


@app.post("/start-analysis")
async def start_analysis(file: UploadFile):
    if not file.filename.endswith(".wav"):
        raise HTTPException(status_code=400, detail="Only .wav files are supported")

    file_path = os.path.join(UPLOAD_DIR, file.filename)
    try:
        with open(file_path, "wb") as f:
            f.write(await file.read())

        result = service.analyze_audio_file(file_path)
        return JSONResponse(content=result.dict())

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

    finally:
        if os.path.exists(file_path):
            os.remove(file_path)


@app.get("/fft-plot")
def get_fft_plot():
    plot_path = "fft_plot.png"
    if not os.path.exists(plot_path):
        raise HTTPException(status_code=404, detail="FFT plot not found")
    return FileResponse(plot_path)


@app.post("/upload-audio/")
async def upload_audio(file: UploadFile):
    with open(f"uploaded_audio/{file.filename}", "wb") as audio_file:
        audio_file.write(await file.read())
    return {"filename": file.filename}


# Home Page
@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    return templates.TemplateResponse("home.html", {"request": request})


# Página 1 - Carregar Áudio
@app.get("/page1", response_class=HTMLResponse)
async def page1(request: Request):
    return templates.TemplateResponse("page1.html", {"request": request})


# Página 2 - Gravar Áudio
@app.get("/page2", response_class=HTMLResponse)
async def page2(request: Request):
    return templates.TemplateResponse("page2.html", {"request": request})


# Página 3 - Carregar Resultados DB
@app.get("/page3", response_class=HTMLResponse)
async def page3(request: Request):
    return templates.TemplateResponse("page3.html", {"request": request})


# Página 4 - Tutorial
@app.get("/page4", response_class=HTMLResponse)
async def page4(request: Request):
    return templates.TemplateResponse("page4.html", {"request": request})

# Página Termo de Consentimento
@app.get("/consent", response_class=HTMLResponse)
async def serve_consent(request: Request):
    return templates.TemplateResponse("consent.html", {"request": request})


@app.get('/favicon.ico', include_in_schema=False)
async def favicon():
    return FileResponse(favicon_path)


# --- frontend/index.html ---
<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PhonIA</title>
    <link rel="stylesheet" href="/static/styles.css">
</head>
<body>
    <header>
        <img src="/static/assets/logo.png" alt="Logotipo" class="logo">
        <img src="/static/assets/phonIA_logo.png" alt="Logotipo" class="logo">
    </header>
    <form id="subtitulo-form">
        <div id="subtitulo">Ferramenta para Detectar Patologias na Voz</div>
    </form>
    <form id="upload-form">
        <input type="file" id="audio-file" accept=".wav" required />
        <button type="submit">Analisar</button>
    </form>
    <div id="result">Aguarde enquanto processamos o arquivo...</div>
    <img id="fft-plot" src="/fft-plot" alt="FFT Plot" style="display:none; margin-top: 20px;">
    <script src="/static/app.js"></script>
</body>
<link rel="manifest" href="/static/assets/manifest.json">
</html>


# --- frontend/styles.css ---
body {
    font-family: Arial, sans-serif;
    text-align: center;
    margin: 20px;
}

header {
    display: flex;
    align-items: center;
    justify-content: center;
    margin-bottom: 20px;
}

.logo {
    height: 80px; /* Ajuste conforme necessário */
    margin-right: 15px;
}

form {
    margin-bottom: 20px;
}

#result {
    margin-top: 20px;
}

/* Estilizar a legenda */
  .legend {
    font-size: 14px; /* Tamanho da fonte */
    font-family: Arial, sans-serif; /* Fonte da legenda */
    color: black; /* Cor do texto da legenda */
    width: 100%;
  }

  /* Ajustar os itens individuais da legenda */
  .legend text {
    font-size: 14px; /* Tamanho do texto dos itens */
  }

  /* Ajustar espaçamento entre os itens */
  .legend g {
    margin-bottom: 10px; /* Espaçamento entre os itens */
    width: 100%;
  }

 /* Botão Padrão */
    button {
        display: inline-flex;
        align-items: center;
        justify-content: center;
        width: 120px;
        height: 40px;
        border: none;
        border-radius: 20px;
        background-color: gray;
        color: white;
        font-size: 16px;
        cursor: pointer;
        position: relative;
        margin: 2 10px;
    }

    button:disabled {
        background-color: lightgray;
        cursor: not-allowed;
    }

    /* Botão Play */
    #playRegionButton::before {
        content: "▶";
        font-size: 28px;
        margin-right: 8px;
    }

    /* Botão de Aplicar Corte */
    #cutButton::before {
        content: "✂";
        font-size: 28px;
        margin-right: 8px;
    }

    .audio-editor {
        text-align: center;
        margin-top: 20px;
    }

    .controls, .audio-controls {
        margin: 20px;
    }

    #waveform {
        border: 1px solid #ccc;
        height: 150px;
        width: 100%;
        margin: auto;
    }

table {
        width: 50%;
        margin: 20px auto;
        border-collapse: collapse;
        text-align: center;
      }
th, td {
        border: 1px solid #ddd;
        padding: 8px;
       }

th {
       background-color: #f4f4f4;
       font-weight: bold;
   }


# --- frontend/audio-editor.js ---
let wavesurfer;
let region = null;

function initializeWaveSurfer(containerId) {
    wavesurfer = WaveSurfer.create({
        container: containerId,
        waveColor: "blue",
        progressColor: "purple",
        cursorColor: "navy",
        height: 150,
        responsive: true,
        plugins: [WaveSurfer.regions.create()]
    });

    return wavesurfer;
}

function loadAudio(file) {
    const reader = new FileReader();
    reader.onload = (event) => {
        wavesurfer.load(event.target.result);
        wavesurfer.on("ready", () => {
            createInitialRegion();
        });
    };
    reader.readAsDataURL(file);
}

function createInitialRegion() {
    region = wavesurfer.addRegion({
        start: 0,
        end: Math.min(5, wavesurfer.getDuration()),
        color: "rgba(0, 255, 0, 0.3)"
    });
}

function playRegion() {
    if (region) {
        wavesurfer.play(region.start, region.end);
    } else {
        alert("Nenhuma região selecionada.");
    }
}

async function cutAudio() {
    if (!region) {
        alert("Por favor, selecione uma região para cortar.");
        return;
    }

    const originalBuffer = wavesurfer.backend.buffer;
    const startSample = Math.floor(region.start * originalBuffer.sampleRate);
    const endSample = Math.floor(region.end * originalBuffer.sampleRate);
    const cutSamples = endSample - startSample;

    if (cutSamples <= 0) {
        alert("Região inválida. Certifique-se de que a região está corretamente definida.");
        return;
    }

    const newBuffer = wavesurfer.backend.ac.createBuffer(
        originalBuffer.numberOfChannels,
        cutSamples,
        originalBuffer.sampleRate
    );

    for (let channel = 0; channel < originalBuffer.numberOfChannels; channel++) {
        const channelData = originalBuffer.getChannelData(channel);
        newBuffer.copyToChannel(channelData.subarray(startSample, endSample), channel);
    }

    await exportAudioBuffer(newBuffer);
}

async function exportAudioBuffer(audioBuffer) {
    const offlineContext = new OfflineAudioContext(
        audioBuffer.numberOfChannels,
        audioBuffer.length,
        audioBuffer.sampleRate
    );

    const source = offlineContext.createBufferSource();
    source.buffer = audioBuffer;
    source.connect(offlineContext.destination);
    source.start();

    const renderedBuffer = await offlineContext.startRendering();
    const wavBlob = bufferToWave(renderedBuffer);

    const link = document.createElement("a");
    link.href = URL.createObjectURL(wavBlob);
    link.download = "cut_audio.wav";
    link.click();
}

function bufferToWave(buffer) {
    const numChannels = buffer.numberOfChannels;
    const length = buffer.length * numChannels * 2 + 44;
    const result = new ArrayBuffer(length);
    const view = new DataView(result);

    writeUTFBytes(view, 0, "RIFF");
    view.setUint32(4, length - 8, true);
    writeUTFBytes(view, 8, "WAVE");
    writeUTFBytes(view, 12, "fmt ");
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, numChannels, true);
    view.setUint32(24, buffer.sampleRate, true);
    view.setUint32(28, buffer.sampleRate * 4, true);
    view.setUint16(32, numChannels * 2, true);
    view.setUint16(34, 16, true);
    writeUTFBytes(view, 36, "data");
    view.setUint32(40, length - 44, true);

    let offset = 44;
    for (let i = 0; i < buffer.length; i++) {
        for (let channel = 0; channel < numChannels; channel++) {
            const sample = buffer.getChannelData(channel)[i];
            const value = Math.max(-1, Math.min(1, sample)) * 32767;
            view.setInt16(offset, value, true);
            offset += 2;
        }
    }
    return new Blob([view], { type: "audio/wav" });
}

function writeUTFBytes(view, offset, string) {
    for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
    }
}


# --- frontend/service-worker.js ---
const CACHE_NAME = "audio-tool-cache-v1";
const urlsToCache = [
    "/",
    "/static/styles.css",
    "/static/app.js",
    "/static/assets/logo-192x192.png",
    "/static/assets/logo-512x512.png"
];

// Instala o Service Worker e adiciona os arquivos ao cache
self.addEventListener("install", (event) => {
    event.waitUntil(
        caches.open(CACHE_NAME).then((cache) => {
            return cache.addAll(urlsToCache);
        })
    );
});

// Responde às requisições com o cache, se disponível
self.addEventListener("fetch", (event) => {
    event.respondWith(
        caches.match(event.request).then((response) => {
            return response || fetch(event.request);
        })
    );
});

// Atualiza o cache quando o Service Worker é ativado
self.addEventListener("activate", (event) => {
    const cacheWhitelist = [CACHE_NAME];
    event.waitUntil(
        caches.keys().then((cacheNames) => {
            return Promise.all(
                cacheNames.map((cacheName) => {
                    if (!cacheWhitelist.includes(cacheName)) {
                        return caches.delete(cacheName);
                    }
                })
            );
        })
    );
});


# --- frontend/app.js ---
// Lógica para enviar o arquivo de áudio e exibir os resultados diretamente
const form = document.getElementById("upload-form");
const resultDiv = document.getElementById("result");
const fftPlot = document.getElementById("fft-plot");
const fftPlotly = document.getElementById("fft-plotly");



// Verifica se o termo de consentimento foi aceito
if (!localStorage.getItem("consentGiven")) {
  alert("Você precisa aceitar o termo de consentimento para continuar.");
  window.location.href = "/consent";
  sessionStorage.setItem("pendingRedirect", link.href);
}

form.addEventListener("submit", async (e) => {
    e.preventDefault();
    const fileInput = document.getElementById("audio-file");
    const file = fileInput.files[0];

    if (!file) return;

    const formData = new FormData();
    formData.append("file", file);

    // Envia o arquivo para análise e exibe os resultados
    try {
        const response = await fetch("/start-analysis", {
            method: "POST",
            body: formData,
        });

        if (response.ok) {
            const data = await response.json();
            resultDiv.innerHTML = `<p>Jitter (local): ${data.localJitter}</p>
                                    <p>Jitter (local, absolute): ${data.localabsoluteJitter}</p>
                                    <p>Jitter (rap): ${data.rapJitter}</p>
                                    <p>Jitter (ppq5): ${data.ppq5Jitter}</p>
                                    <p>Jitter (ddp): ${data.ddpJitter}</p>
                                    <p>Shimmer (local): ${data.localShimmer}</p>
                                    <p>Shimmer (local, dB): ${data.localdbShimmer}</p>
                                    <p>Shimmer (apq3): ${data.apq3Shimmer}</p>
                                    <p>Shimmer (apq5): ${data.apq5Shimmer}</p>
                                    <p>Shimmer (apq11): ${data.apq11Shimmer}</p>
                                    <p>Shimmer (dda): ${data.ddaShimmer}</p>
                                    <p>Fundamental Frequency: ${data.fundamental_frequency}</p>
                                    <p>HNR: ${data.hnr}</p>`;
            fftPlot.style.display = "block";
            fftPlotly.style.display = "block";

            const results = [
            { freq: "Jitter (ppq5)", amp: 1.11 },
            { freq: "Shimmer (apq3)", amp: 2.22 },
            { freq: "Frequência Fundamental (Hz)", amp: 3.33 },
            { freq: "HNR (Harmonic-to-Noise Ratio)", amp: 4.44 }
            ];

            const results2 = [
            { metrica: "Jitter (ppq5)", valor: data.jitter },
            { metrica: "Shimmer (apq3)", valor: data.shimmer },
            { metrica: "Frequência Fundamental (Hz)", valor: data.fundamental_frequency },
            { metrica: "HNR (Harmonic-to-Noise Ratio)", valor: data.hnr }
            ];

//            // Verificar se as listas têm o mesmo tamanho
//            if (data.frequencies.length !== data.amplitudes.length) {
//                console.error("As listas de frequências e amplitudes têm tamanhos diferentes!");
//            } else {
//                // Criar um dicionário combinando os itens das listas
//                const results = data.frequencies.map((freq, index) => {
//                    return {
//                        freq: freq,
//                        amp: data.amplitudes[index]
//                    };
//                });
//
//            console.log(results);

            // Chama a função para criar a tabela com os dados
            criarTabela(results);
            criarTabela_fft(results2);

        } else {
            const error = await response.json();
            resultDiv.innerHTML = `<p>Error: ${error.detail}</p>`;
        }
    } catch (error) {
        resultDiv.innerHTML = `<p>Error: ${error.message}</p>`;
    }
});


        // Função para criar e inserir a tabela
        function criarTabela(dados) {
            // Cria o elemento da tabela
            const tabela = document.createElement("table");

            // Cabeçalho da tabela
            const thead = document.createElement("thead");
            thead.innerHTML = `
                <tr>
                    <th>Frequência [Hz]</th>
                    <th>Amplitude</th>
                </tr>
            `;
            tabela.appendChild(thead);

            // Corpo da tabela
            const tbody = document.createElement("tbody");
            dados.forEach((item) => {
                const row = document.createElement("tr");
                row.innerHTML = `
                    <td>${item.freq}</td>
                    <td>${item.amp}</td>
                `;
                tbody.appendChild(row);
            });
            tabela.appendChild(tbody);

            // Insere a tabela no contêiner
            document.getElementById("tabela-resultados").appendChild(tabela);
        }

                // Função para criar e inserir a tabela
        function criarTabela_fft(dados) {
            // Cria o elemento da tabela
            const tabela = document.createElement("table");

            // Cabeçalho da tabela
            const thead = document.createElement("thead");
            thead.innerHTML = `
                <tr>
                    <th>Métrica2</th>
                    <th>Valor2</th>
                </tr>
            `;
            tabela.appendChild(thead);

            // Corpo da tabela
            const tbody = document.createElement("tbody");
            dados.forEach((item) => {
                const row = document.createElement("tr");
                row.innerHTML = `
                    <td>${item.metrica}</td>
                    <td>${item.valor}</td>
                `;
                tbody.appendChild(row);
            });
            tabela.appendChild(tbody);

            // Insere a tabela no contêiner
            document.getElementById("tabela-resultados_fft").appendChild(tabela);
        }



# --- frontend/templates/base.html ---
<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PhonIA</title>
    <link rel="stylesheet" href="/static/styles.css">
</head>
<script>
  // Desabilita os links enquanto não houver consentimento
  if (!localStorage.getItem("consentGiven")) {
    document.querySelectorAll("nav a").forEach(link => {
      link.addEventListener("click", (e) => {
        e.preventDefault();
        alert("aaVocê precisa aceitar o termo de consentimento para acessar esta página.");
        window.location.href = "/consent";
      });
    });
  }
</script>
<body>
    <meta charset="UTF-8">
    <header>
        <img src="/static/assets/logo.png" alt="Logotipo" class="logo">
        <img src="/static/assets/phonIA_logo.png" alt="Logotipo" class="logo">
        <nav>
            <a href="/">Início</a> |
            <a href="/page1">Carregar</a> |
            <a href="/page2">Gravar</a> |
            <a href="/page3">Resultados</a> |
            <a href="/page4">Tutorial</a> |
            <a href="/consent">Consentimento</a>
        </nav>
    </header>
    <main>
        {% block content %}{% endblock %}
    </main>
    <footer>
        <p>&copy; 2025 PhonIA WebApp</p>
    </footer>
</body>
<link rel="manifest" href="/static/assets/manifest.json">
</html>



# --- frontend/templates/consent.html ---
{% extends "base.html" %}

{% block content %}
  <link rel="stylesheet" href="/static/styles.css">
  <style>
    #user-info-popup {
      display: none;
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      background: #fff;
      padding:50px;
      border: 1px solid #ccc;
      box-shadow: 0 0 10px rgba(0,0,0,0.3);
      z-index: 1000;
    }
    #popup-overlay {
      display: none;
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background: rgba(0,0,0,0.5);
      z-index: 999;
    }
  </style>
<body>
  <div class="container">
    <h1>Termo de Consentimento</h1>
    <p>
      Ao prosseguir, você concorda que os dados de áudio enviados serão utilizados exclusivamente para fins de análise e pesquisa. Nenhum dado será compartilhado com terceiros sem sua autorização.
    </p>
    <label>
      <input type="checkbox" id="consent-checkbox">
      Eu li e concordo com os termos de consentimento.
    </label>
    <br><br>
    <button id="continue-btn" disabled>Continuar</button>
  </div>
  <div id="popup-overlay"></div>
  <div id="user-info-popup">
    <h3>Informe seus dados para realizar cadastro na plataforma:</h3>
    <input type="text" id="numero" placeholder="Número Registro"><br><br>
    <input type="text" id="problem" placeholder="Problema Diagnosticado? (Sim/Não)"><br><br>
    <input type="text" id="trata" placeholder="Faz Tratamento? (Sim/Não)"><br><br>
    <input type="text" id="age" placeholder="Idade"><br><br>
    <input type="text" id="occupation" placeholder="Profissão"><br><br>
    <button id="submit-user-info">Enviar</button>
  </div>
  <script>
    // Reseta o consentimento toda vez que o app inicia
    localStorage.removeItem("consentGiven");

    const checkbox = document.getElementById("consent-checkbox");
    const button = document.getElementById("continue-btn");
    const overlay = document.getElementById("popup-overlay");
    const popup = document.getElementById("user-info-popup");
    const submitUserInfo = document.getElementById("submit-user-info");
    const redirectTo = sessionStorage.getItem("pendingRedirect") || "/";

    checkbox.addEventListener("change", () => {
      button.disabled = !checkbox.checked;
    });

    button.addEventListener("click", () => {
      // Exibe o popup de dados do usuário
      overlay.style.display = "block";
      popup.style.display = "block";
<!--      localStorage.setItem("consentGiven", "true");-->
<!--      window.location.href = "/";-->
    });

      submitUserInfo.addEventListener("click", () => {
      const numero = document.getElementById("numero").value;
      const problem = document.getElementById("problem").value;
      const trata = document.getElementById("trata").value;
      const age = document.getElementById("age").value;
      const occupation = document.getElementById("occupation").value;

      if (!numero || !problem || !trata  || !age || !occupation) {
        alert("Por favor, preencha todos os campos.");
        return;
      }

      // Aqui você pode salvar os dados localmente ou enviar para o backend
      console.log({ numero, problem, trata, age, occupation });

      localStorage.setItem("consentGiven", "true");
      sessionStorage.removeItem("pendingRedirect");
      window.location.href = redirectTo;
    });
</script>
</body>
{% endblock %}



# --- frontend/templates/home.html ---
{% extends "base.html" %}

{% block content %}
<div class="centered-container">
    <h2>Ferramenta para Detectar Patologias na Voz</h2>
    <p>Selecione a opção desejada:</p>
    <div class="button-list">
        <button onclick="location.href='/page1'">Carregar áudio</button>
        <button onclick="location.href='/page2'">Gravar áudio</button>
        <button onclick="location.href='/page3'">Resultados DB</button>
        <button onclick="location.href='/page4'">Tutorial</button>
        <button onclick="localStorage.removeItem('consentGiven'); window.location.href='/consent';">Visualizar Termo</button>
        <button onclick="localStorage.removeItem('consentGiven'); window.location.href='/';">Sair</button>

    </div>
</div>
<style>
    .centered-container {
        text-align: center;
    }
    .button-list {
        display: flex;
        flex-direction: column;
        align-items: center;
        gap: 10px; /* Espaçamento entre os botões */
    }
    .button-list button {
        padding: 10px 20px;
        font-size: 16px;
        cursor: pointer;
    }
</style>
<script>
  document.querySelectorAll("nav a").forEach(link => {
    link.addEventListener("click", (e) => {
      if (!localStorage.getItem("consentGiven")) {
        e.preventDefault();
        sessionStorage.setItem("pendingRedirect", link.href);
        alert("Você precisa aceitar o termo de consentimento antes de acessar esta página.");
        window.location.href = "/consent";
      }
    });
  });
</script>
{% endblock %}



# --- frontend/templates/page1.html ---
{% extends "base.html" %}

{% block content %}
<script src="https://unpkg.com/wavesurfer.js@5.2.0"></script>
<script src="https://unpkg.com/wavesurfer.js@5.2.0/dist/plugin/wavesurfer.regions.min.js"></script>
<script src="/static/audio-editor.js"></script>

<h2>Carregar e Editar Áudio</h2>
<p>Importe o áudio para realizar análise e edição. (somente .wav)</p>

<form id="upload-form">
    <input type="file" id="audio-file" accept=".wav" required />
    <button type="button" id="loadButton">Carregar Áudio</button>
    <button type="submit">Analisar</button>
</form>

<div id="result">Aguarde enquanto processamos o arquivo...</div>
<div id="waveform" style="margin-top: 20px;"></div>

<meta charset="UTF-8">
<!-- Contêiner onde a tabela será inserida -->
<div id="tabela-resultados"></div>
<div id="tabela-resultados_fft"></div>

<div class="audio-controls">
    <button id="playRegionButton" disabled>Ouvir Áudio</button>
    <button id="cutButton" disabled>Cortar Áudio</button>
</div>
<script>
    document.addEventListener("DOMContentLoaded", () => {
        const audioFileInput = document.getElementById("audio-file");
        const loadButton = document.getElementById("loadButton");
        const uploadForm = document.getElementById("upload-form");
        const resultDiv = document.getElementById("result");
        const fftPlot = document.getElementById("fft-plot");
        const fftPloly = document.getElementById("fft-plotly");
        const playRegionButton = document.getElementById("playRegionButton");
        const cutButton = document.getElementById("cutButton");
        wavesurfer = initializeWaveSurfer("#waveform");
        fftPlot.style.display = "none";
        fftPlotly.style.display = "none";

        // Carregar áudio no WaveSurfer
        loadButton.addEventListener("click", () => {
            const file = audioFileInput.files[0];
            if (!file) {
                alert("Por favor, selecione um arquivo .wav.");
                return;
            }
            resultDiv.textContent = "Processando o arquivo...";
            fftPlot.style.display = "none";
            fftPlotly.style.display = "none";
            loadAudio(file);
            playRegionButton.disabled = false;
            cutButton.disabled = false;
        });


        // Controles de edição
        playRegionButton.addEventListener("click", playRegion);
        cutButton.addEventListener("click", cutAudio);
    });
</script>
<img id="fft-plot" src="/fft-plot" alt="FFT Plot" style="display:none; margin-top: 20px;">
<iframe id="fft-plotly" src="/static/assets/grafico_interativo.html" width="100%" height="500px" frameborder="0"></iframe>
<script src="/static/app.js"></script>
<!--<script>-->
<!--    // Reseta o consentimento toda vez que o app inicia-->
<!--    localStorage.removeItem("consentGiven");-->
<!--</script>-->
{% endblock %}



# --- frontend/templates/page2.html ---
{% extends "base.html" %}

{% block content %}
<script src="https://unpkg.com/wavesurfer.js@5.2.0"></script>
<script src="https://unpkg.com/wavesurfer.js@5.2.0/dist/plugin/wavesurfer.regions.min.js"></script>
<script src="/static/audio-editor.js"></script>
<script src="/static/app.js"></script>
<!--<script>-->
<!--    // Reseta o consentimento toda vez que o app inicia-->
<!--    localStorage.removeItem("consentGiven");-->
<!--</script>-->

<div class="audio-editor">
    <h2>Gravar e Editar Áudio</h2>
    <div id="waveform" style="margin-top: 20px;"></div>
    <div id="statusMessage" style="margin-top: 20px; color: green;"></div>
    <div class="audio-controls">
        <button id="recordButton">Iniciar Gravação</button>
        <button id="stopButton" disabled>Parar Gravação</button>
        <button id="playRegionButton" disabled>Ouvir Áudio</button>
        <button id="cutButton" disabled>Cortar Áudio</button>
    </div>
</div>

<style>
    /* Botão de gravação */
    #recordButton {
        display: inline-flex;
        align-items: center;
        justify-content: center;
        width: 120px;
        height: 40px;
        border: none;
        border-radius: 20px;
        background-color: gray;
        color: white;
        font-size: 16px;
        cursor: pointer;
        position: relative;
    }

    #recordButton.recording {
        background-color: red;
        animation: blink 1s infinite;
    }

    @keyframes blink {
        0%, 50% {
            background-color: red;
        }
        50%, 100% {
            background-color: gray;
        }
    }
</style>

<script>
    let isRecording = false;
    let audioContext;
    let mediaRecorder;
    let audioChunks = [];
    let mediaStream;

    document.addEventListener("DOMContentLoaded", () => {
        const recordButton = document.getElementById("recordButton");
        const stopButton = document.getElementById("stopButton");
        const playRegionButton = document.getElementById("playRegionButton");
        const cutButton = document.getElementById("cutButton");

        wavesurfer = initializeWaveSurfer("#waveform");

        const resetRecordingState = () => {
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }

            if (wavesurfer) {
                wavesurfer.empty();
                wavesurfer.clearRegions();
            }

            audioChunks = [];
            isRecording = false;

            recordButton.classList.remove("recording");
            recordButton.disabled = false;
            stopButton.disabled = true;
            playRegionButton.disabled = true;
            cutButton.disabled = true;
        };

        // Gravação de áudio
        recordButton.addEventListener("click", async () => {
            if (isRecording) return;

            resetRecordingState(); // Reinicia tudo antes de gravar
            isRecording = true;
            recordButton.classList.add("recording");
            recordButton.disabled = true;
            stopButton.disabled = false;

            try {
                mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(mediaStream, { mimeType: "audio/webm" });
                audioContext = new (window.AudioContext || window.webkitAudioContext)();

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = async () => {
                    const blob = new Blob(audioChunks, { type: "audio/webm" });
                    audioChunks = [];
                    wavesurfer.loadBlob(blob);

                    wavesurfer.on("ready", () => {
                        playRegionButton.disabled = false;
                        cutButton.disabled = false;
                        createInitialRegion();
                    });
                };

                mediaRecorder.start();
            } catch (error) {
                alert("Erro ao acessar o microfone.");
                console.error(error);
                resetRecordingState();
            }
        });

        stopButton.addEventListener("click", () => {
            if (mediaRecorder && mediaRecorder.state !== "inactive") {
                mediaRecorder.stop();
            }
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            alert("Gravação encerrada!");
            isRecording = false;
            recordButton.classList.remove("recording");
            recordButton.disabled = false;
            stopButton.disabled = true;
        });

        // Controles de edição
        playRegionButton.addEventListener("click", playRegion);
        cutButton.addEventListener("click", cutAudio);
    });
</script>
{% endblock %}



# --- frontend/templates/page3.html ---
{% extends "base.html" %}

{% block content %}
<script src="/static/app.js"></script>
<!--<script>-->
<!--    // Reseta o consentimento toda vez que o app inicia-->
<!--    localStorage.removeItem("consentGiven");-->
<!--</script>-->
<h2>Pag 3 - Ver resultados DB</h2>
<p>This is the content of Page 3.</p>
{% endblock %}



# --- frontend/templates/page4.html ---
{% extends "base.html" %}

{% block content %}
<script src="/static/app.js"></script>
<!--<script>-->
<!--    // Reseta o consentimento toda vez que o app inicia-->
<!--    localStorage.removeItem("consentGiven");-->
<!--</script>-->
<h2>Pag 4 - Tutorial</h2>
<p>This is the content of Page 4.</p>
{% endblock %}



# --- frontend/assets/manifest.json ---
{
  "name": "Ferramenta de Detectar Patologias na Voz - PhonIA",
  "short_name": "PhonIA",
  "description": "Uma ferramenta que faz análise de áudio analisando parâmetros como jitter, shimmer e FFT do sinal de áudio bem como a aplicação de IA para detecção de patologias na voz.",
  "icons": [
    {
      "src": "/static/assets/logo-192x192.png",
      "sizes": "192x192",
      "type": "image/png"
    },
    {
      "src": "/static/assets/logo-512x512.png",
      "sizes": "512x512",
      "type": "image/png"
    }
  ],
  "start_url": "http://127.0.0.1:8000",
  "display": "standalone",
  "background_color": "#ffffff",
  "theme_color": "#000000"
}



# --- api/main.py ---
from mangum import Mangum  # Adiciona compatibilidade com serverless
from adapters.web import app as fastapi_app  # Importa módulos

app = fastapi_app  # O app existente no projeto
handler = Mangum(app)  # Configuração necessária para o Vercel
