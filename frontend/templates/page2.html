{% extends "base.html" %}

{% block content %}
<!-- Importar WaveSurfer.js e o plugin Regions -->
<script src="https://unpkg.com/wavesurfer.js@5.2.0"></script>
<script src="https://unpkg.com/wavesurfer.js@5.2.0/dist/plugin/wavesurfer.regions.min.js"></script>
<div class="audio-editor">
    <h2>Pag 2 - Gravar áudio</h2>
    <div class="controls">
        <button id="recordButton">Start Recording</button>
        <button id="stopButton" disabled>Stop Recording</button>
    </div>
    <div id="waveform" style="margin-top: 20px;"></div>
    <div id="statusMessage" style="margin-top: 20px; color: green;"></div>
    <div class="audio-controls">
        <button id="playRegionButton" disabled>Play Region</button>
        <button id="cutButton" disabled>Apply Cut</button>
    </div>
</div>

<style>
    .audio-editor {
        text-align: center;
        margin-top: 20px;
    }
    .controls, .audio-controls {
        margin: 20px;
    }
    #waveform {
        border: 1px solid #ccc;
        height: 150px;
        width: 100%;
        margin: auto;
    }
</style>

<script>
    let audioContext;
    let mediaRecorder;
    let audioChunks = [];
    let wavesurfer;
    let mediaStream;
    let duration = 0;
    let region = null;

    document.addEventListener("DOMContentLoaded", () => {
        const recordButton = document.getElementById("recordButton");
        const stopButton = document.getElementById("stopButton");
        const playRegionButton = document.getElementById("playRegionButton");
        const cutButton = document.getElementById("cutButton");
        const waveformContainer = document.getElementById("waveform");
        const statusMessage = document.getElementById("statusMessage");

        // Inicializar WaveSurfer com o plugin Regions
        wavesurfer = WaveSurfer.create({
            container: waveformContainer,
            waveColor: "blue",
            progressColor: "purple",
            cursorColor: "navy",
            height: 150,
            responsive: true,
            plugins: [
                WaveSurfer.regions.create()
            ]
        });

        // Iniciar gravação
        recordButton.addEventListener("click", async () => {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            navigator.mediaDevices.getUserMedia({ audio: true })
            .then(stream => console.log("Microphone access granted"))
            .catch(error => console.error("Microphone access denied:", error));
            mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(mediaStream, { mimeType: "audio/webm" });

            mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    audioChunks.push(event.data);
                }
                console.log("Chunk size:", event.data.size);
            };

            mediaRecorder.onstop = async () => {
                const blob = new Blob(audioChunks, { type: "audio/webm" });
                console.log("Final blob size:", blob.size);

                if (blob.size === 0) {
                    alert("Audio recording failed. Please try again.");
                    return;
                    }

                audioChunks = [];
                const arrayBuffer = await blob.arrayBuffer();
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

                console.log("Audio buffer byte length:", arrayBuffer.byteLength);
                if (arrayBuffer.byteLength === 0) {
                    //alert("ArrayBuffer is empty. Check the recording process.");
                    return;
                    }

                // Carregar áudio no WaveSurfer
                wavesurfer.loadBlob(blob);

                // Mostrar mensagem quando a forma de onda estiver pronta
                wavesurfer.on("ready", () => {
                    duration = wavesurfer.getDuration();
                    cutButton.disabled = false;
                    playRegionButton.disabled = false;

                    const backendBuffer = wavesurfer.backend.buffer;
                    if (!backendBuffer) {
                        console.error("WaveSurfer backend buffer is empty.");
                        return;
                    }

                    console.log("Buffer Sample Rate:", backendBuffer.sampleRate);
                    console.log("Buffer Duration:", backendBuffer.duration);
                    console.log("Number of Channels:", backendBuffer.numberOfChannels);

                    // Adicionar região inicial
                    region = wavesurfer.addRegion({
                        start: 0,
                        end: Math.min(5, duration), // Por padrão, primeiros 5 segundos
                        color: "rgba(0, 255, 0, 0.3)"
                    });
                });
            };

            mediaRecorder.start();
            recordButton.disabled = true;
            stopButton.disabled = false;
        });

        // Parar gravação
        stopButton.addEventListener("click", () => {
            if (mediaRecorder && mediaRecorder.state !== "inactive") {
                mediaRecorder.stop();
            }

            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }

            recordButton.disabled = false;
            stopButton.disabled = true;
        });

        // Ouvir região
        playRegionButton.addEventListener("click", () => {
            if (region) {
                wavesurfer.play(region.start, region.end);
            } else {
                alert("No region selected.");
            }
        });

        // Aplicar corte
        cutButton.addEventListener("click", async () => {
            if (!region) {
                alert("Please select a region to cut.");
                return;
            }

            const originalBuffer = wavesurfer.backend.buffer;
            if (!originalBuffer) {
                alert("Audio buffer is not available.");
                return;
            }

                console.log("Original Buffer Sample Rate:", originalBuffer.sampleRate);
                console.log("Original Buffer Duration:", originalBuffer.duration);
                console.log("Number of Channels:", originalBuffer.numberOfChannels);

            const sampleRate = originalBuffer.sampleRate;
            const startSample = Math.floor(region.start * sampleRate);
            const endSample = Math.floor(region.end * sampleRate);
            const cutSamples = endSample - startSample;

            console.log(`Cutting audio from ${region.start}s to ${region.end}s`);
            console.log(`Start Sample: ${startSample}, End Sample: ${endSample}, Total Samples: ${cutSamples}`);

            if (cutSamples <= 0) {
                alert("Invalid region. Please ensure the region is correctly defined.");
                return;
            }

            // Criar um novo buffer para o trecho cortado
            const newBuffer = audioContext.createBuffer(
                originalBuffer.numberOfChannels,
                cutSamples,
                sampleRate
            );

            for (let channel = 0; channel < originalBuffer.numberOfChannels; channel++) {
                const channelData = originalBuffer.getChannelData(channel);
                const cutChannelData = newBuffer.getChannelData(channel);
                cutChannelData.set(channelData.subarray(startSample, endSample));
            }

            console.log("Audio loaded buffer original, size:", originalBuffer.byteLength);
            console.log("Audio loaded novo  buffer, size:", newBuffer.byteLength);

            // Converter para WAV e iniciar download
            const wavBlob = bufferToWave(newBuffer);
            const url = URL.createObjectURL(wavBlob);

            const link = document.createElement("a");
            link.href = url;
            link.download = "cut_audio.wav";
            link.click();
        });

        // Função auxiliar para converter buffer em WAV
        function bufferToWave(buffer) {
            const length = buffer.length * buffer.numberOfChannels * 2 + 44;
            const result = new ArrayBuffer(length);
            const view = new DataView(result);

            writeWAVHeader(view, buffer);

            let offset = 44;
            for (let i = 0; i < buffer.numberOfChannels; i++) {
                const channelData = buffer.getChannelData(i);
                for (let sample of channelData) {
                    const value = Math.max(-1, Math.min(1, sample));
                    view.setInt16(offset, value < 0 ? value * 0x8000 : value * 0x7FFF, true);
                    offset += 2;
                }
            }

            return new Blob([result], { type: "audio/wav" });
        }

        function writeWAVHeader(view, buffer) {
            const sampleRate = buffer.sampleRate;
            const numChannels = buffer.numberOfChannels;
            const byteRate = sampleRate * numChannels * 2;

            view.setUint32(0, 0x46464952, false); // "RIFF"
            view.setUint32(4, 36 + buffer.length * numChannels * 2, true);
            view.setUint32(8, 0x45564157, false); // "WAVE"
            view.setUint32(12, 0x20746d66, false); // "fmt "
            view.setUint32(16, 16, true); // Subchunk1Size
            view.setUint16(20, 1, true); // AudioFormat
            view.setUint16(22, numChannels, true); // NumChannels
            view.setUint32(24, sampleRate, true); // SampleRate
            view.setUint32(28, byteRate, true); // ByteRate
            view.setUint16(32, numChannels * 2, true); // BlockAlign
            view.setUint16(34, 16, true); // BitsPerSample
            view.setUint32(36, 0x61746164, false); // "data"
            view.setUint32(40, buffer.length * numChannels * 2, true);
        }
    });
</script>
{% endblock %}
